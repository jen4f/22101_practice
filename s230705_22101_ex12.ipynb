{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659445c8",
   "metadata": {},
   "source": [
    "## L12: Dictionaries\n",
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584bf2fe",
   "metadata": {},
   "source": [
    "1\\. Create a dictionary where the keys are codons and the value are the one-letter-code for the amino acids. The dictionary will function as a look-up table. You can find a codon list here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c321fea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary printed below contains codons as keys, SLC as values :):\n",
      "{('ATT', 'ATC', 'ATA'): 'I', ('CTT', 'CTC', 'CTA', 'CTG', 'TTA', 'TTG'): 'L', ('GTT', 'GTC', 'GTA', 'GTG'): 'V', ('TTT', 'TTC'): 'F', 'ATG': 'M', ('TGT', 'TGC'): 'C', ('GCT', 'GCC', 'GCA', 'GCG'): 'A', ('GGT', 'GGC', 'GGA', 'GGG'): 'G', ('CCT', 'CCC', 'CCA', 'CCG'): 'P', ('ACT', 'ACC', 'ACA', 'ACG'): 'T', ('TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'): 'S', ('TAT', 'TAC'): 'Y', 'TGG': 'W', ('CAA', 'CAG'): 'Q', ('AAT', 'AAC'): 'N', ('CAT', 'CAC'): 'H', ('GAA', 'GAG'): 'E', ('GAT', 'GAC'): 'D', ('AAA', 'AAG'): 'K', ('CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'): 'R', ('TAA', 'TAG', 'TGA'): 'Stop'}\n"
     ]
    }
   ],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "make an empty dictionary using dict()\n",
    "make two lists\n",
    "learn how to make two into a dict().\n",
    "\"\"\"\n",
    "# code\n",
    "\n",
    "# keys are codons:\n",
    "codons_as_keys = list()\n",
    "codons_as_keys = [(\"ATT\", \"ATC\", \"ATA\"), (\"CTT\", \"CTC\", \"CTA\", \"CTG\", \"TTA\", \"TTG\"), (\"GTT\", \"GTC\", \"GTA\", \"GTG\"), (\"TTT\", \"TTC\"), (\"ATG\"), (\"TGT\", \"TGC\"), (\"GCT\", \"GCC\", \"GCA\", \"GCG\"), (\"GGT\", \"GGC\", \"GGA\", \"GGG\"), (\"CCT\", \"CCC\", \"CCA\", \"CCG\"), (\"ACT\", \"ACC\", \"ACA\", \"ACG\"), (\"TCT\", \"TCC\", \"TCA\", \"TCG\", \"AGT\", \"AGC\"), (\"TAT\", \"TAC\"), (\"TGG\"), (\"CAA\", \"CAG\"), (\"AAT\", \"AAC\"), (\"CAT\", \"CAC\"), (\"GAA\", \"GAG\"), (\"GAT\", \"GAC\"), (\"AAA\", \"AAG\"), (\"CGT\", \"CGC\", \"CGA\", \"CGG\", \"AGA\", \"AGG\"), (\"TAA\", \"TAG\", \"TGA\")]\n",
    "SLC_as_values = list()\n",
    "SLC_as_values = [\"I\", \"L\", \"V\", \"F\", \"M\", \"C\", \"A\", \"G\", \"P\", \"T\", \"S\", \"Y\", \"W\", \"Q\", \"N\", \"H\", \"E\", \"D\", \"K\", \"R\", \"Stop\"]\n",
    "\n",
    "codon_SLC_dict = dict(zip(codons_as_keys, SLC_as_values))\n",
    "print(\"The dictionary printed below contains codons as keys, SLC as values :):\")\n",
    "print(codon_SLC_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3169593",
   "metadata": {},
   "source": [
    "2\\. Use the dictionary from the previous exercise in a program, that translates all the nucleotide fasta entries in dna7.fsa to amino acid sequence. Save the results in a file aa7.fsa in fasta format. Remember to keep the 'headlines' for each entry and add 'Amino Acid Sequence' to each of them. The STOP codon is NOT a part of the amino acid sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bedeefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "include dictionary in exercicse\n",
    "set the stop codons apart so we can look for them later:\n",
    "    create a list of dictionary items using the .items() method\n",
    "    for each of key, value pair in the items list:\n",
    "        if the value is \"Stop:\n",
    "            then, we can create a variable named stop_codons, which equals to k :).\n",
    "\n",
    "\n",
    "initiate an empty head_line_aa_as_list\n",
    "initiate an empty dna_sequences_as_list\n",
    "with open the nucleotide fasta file\n",
    "    for each line\n",
    "        if the line starts with \">\", \n",
    "            add to the end, or change the end of the line to contain \" Amino Acid Sequence\"\n",
    "            append it to the head_line list.\n",
    "        else if the line starts with a sequence list,\n",
    "            append it to the sequence_list.\n",
    "\n",
    "initiate an empty aa_sequences list:\n",
    "for dna_sequence in dna_sequence list:\n",
    "    use my own function to translate, it returns one aa sequence as one string.\n",
    "    we will append this to the aa_sequences list, creating a list of strings.\n",
    "\n",
    "\n",
    "how my dna_sequence to aa_sequence function works:\n",
    "input a dna_sequence as a string, outputs an aa_sequence as a string.\n",
    "need to input the dict itself and the stop codon variable \n",
    "so we have with something like:\n",
    "def dna_seq_to_aa(dna_seq, codon_dict, stop_codon):\n",
    "    initiate an empty string for aa_sequence\n",
    "    for position in range(len(dna_seq)-2):    # use -2 to prevent index errors later.\n",
    "        one_codon = random_sequence[position:position+3]\n",
    "        if one_codon in stop_codons:\n",
    "            break\n",
    "        else:\n",
    "            for k, v in dict_item_list:\n",
    "                if one_codon in k:\n",
    "                    aa_sequence += v\n",
    "            position += 4\n",
    "    return aa_sequence.\n",
    "\"\"\"\n",
    "# code\n",
    "def main():\n",
    "    # include the codon dictionary\n",
    "    # keys are codons\n",
    "    codons_as_keys = list()\n",
    "    codons_as_keys = [(\"ATT\", \"ATC\", \"ATA\"), (\"CTT\", \"CTC\", \"CTA\", \"CTG\", \"TTA\", \"TTG\"), (\"GTT\", \"GTC\", \"GTA\", \"GTG\"), (\"TTT\", \"TTC\"), (\"ATG\"), (\"TGT\", \"TGC\"), (\"GCT\", \"GCC\", \"GCA\", \"GCG\"), (\"GGT\", \"GGC\", \"GGA\", \"GGG\"), (\"CCT\", \"CCC\", \"CCA\", \"CCG\"), (\"ACT\", \"ACC\", \"ACA\", \"ACG\"), (\"TCT\", \"TCC\", \"TCA\", \"TCG\", \"AGT\", \"AGC\"), (\"TAT\", \"TAC\"), (\"TGG\"), (\"CAA\", \"CAG\"), (\"AAT\", \"AAC\"), (\"CAT\", \"CAC\"), (\"GAA\", \"GAG\"), (\"GAT\", \"GAC\"), (\"AAA\", \"AAG\"), (\"CGT\", \"CGC\", \"CGA\", \"CGG\", \"AGA\", \"AGG\"), (\"TAA\", \"TAG\", \"TGA\")]\n",
    "    # values are SLC.\n",
    "    SLC_as_values = list()\n",
    "    SLC_as_values = [\"I\", \"L\", \"V\", \"F\", \"M\", \"C\", \"A\", \"G\", \"P\", \"T\", \"S\", \"Y\", \"W\", \"Q\", \"N\", \"H\", \"E\", \"D\", \"K\", \"R\", \"Stop\"]\n",
    "\n",
    "    codon_SLC_dict = dict(zip(codons_as_keys, SLC_as_values))\n",
    "    # save the stop codons as a variable for later use\n",
    "    usr_dict_items_list = codon_SLC_dict.items()\n",
    "    for k, v in usr_dict_items_list:\n",
    "        if v == \"Stop\":\n",
    "            usr_stop_codons = k\n",
    "\n",
    "\n",
    "    # aquire the sequence we need:\n",
    "    # we need dna sequences as continues strings for translation\n",
    "    # because line breaks can occur in the middel of a codon reading frame.\n",
    "    headers_with_aa_edit_list = []\n",
    "    dna_sequences_as_list = []\n",
    "    dna_sequences_as_str = \"\"\n",
    "    with open (\"dna7.fsa\", \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                headers_with_aa_edit_list.append(line.replace(\"\\n\", \" Amino Acid Sequence\\n\"))\n",
    "                line = \">\"\n",
    "            else:\n",
    "                pass\n",
    "            dna_sequences_as_str += line.strip()\n",
    "    \n",
    "    dna_sequences_list = dna_sequences_as_str.split(\">\")\n",
    "    dna_sequences_list.pop(0)\n",
    "\n",
    "    aa_sequences_list = []\n",
    "    for dna_sequence in dna_sequences_list:\n",
    "        aa_sequences_list.append(dna_seq_to_aa_seq(dna_sequence, usr_dict_items_list, usr_stop_codons))\n",
    "    # sanity check:\n",
    "    # print(aa_sequences_list)\n",
    "    \n",
    "\n",
    "# write out the two lists into a file called aa7.fsa\n",
    "    with open(\"aa7.fsa\", \"w\") as outfile:\n",
    "        for position in range(len(headers_with_aa_edit_list)):\n",
    "            outfile.write(headers_with_aa_edit_list[position])\n",
    "            outfile.write(aa_sequences_list[position]+\"\\n\")\n",
    "\n",
    "def dna_seq_to_aa_seq(dna_seq, dict_item_list, stop_codons):\n",
    "    aa_sequence = \"\"\n",
    "    for position in range(0, len(dna_seq), 3):    # use -2 to prevent index errors later.\n",
    "        one_codon = dna_seq[position:position+3]\n",
    "        if one_codon in stop_codons:\n",
    "            break\n",
    "        else:\n",
    "            for k, v, in dict_item_list:\n",
    "                if one_codon in k:\n",
    "                    aa_sequence += v\n",
    "            position += 4\n",
    "    return aa_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389fa643",
   "metadata": {},
   "source": [
    "3\\. In the file ex5.acc are a lot of accession numbers, where some are duplicates. Earlier we just removed the duplicates, now we should count them. Make a program that reads the file once, and writes a file noorder5.acc with the unique accession numbers and the number of occurrences in the file. A line should look like this: \"AC24677 2\", if this accession occurs twice in ex5.acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d865594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "make use of the .get() method in the dictionary\n",
    "it is like the one where you count dna nucleotide occurences!\n",
    "realise that \"...with unique accession numbers, you get unique accession numbers by the dict keys\"\n",
    "you don't need some other thing to filted out and get the unique accession numbers.\n",
    "\n",
    "initiate a dictionary used to count occurences\n",
    "with open some new file as outfile:\n",
    "    with open the file as in file:\n",
    "        for line in line:\n",
    "            if line in dict:\n",
    "                dict[line] += 1    # the value of the key is the counter\n",
    "            else:\n",
    "                dict[line] = 1    # if this key is found for the first time, we set the value to be 1 :).\n",
    "        # set it out like this\n",
    "        ac_counter_list = dict.items()\n",
    "    outfile.write(iterate correcrlt over ac_counter_list)\n",
    "\"\"\"\n",
    "# code\n",
    "\n",
    "ac_num_counter_dict = dict()\n",
    "with open(\"noorder5.acc\", \"w\") as outfile:\n",
    "    with open(\"ex5.acc\", \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line in ac_num_counter_dict:\n",
    "                # the value of the key is the counter.\n",
    "                ac_num_counter_dict[line] += 1\n",
    "            else:\n",
    "                # if this key is found for the first time,\n",
    "                # we set the value to be 1.\n",
    "                ac_num_counter_dict[line] = 1\n",
    "        ac_num_counter_list = ac_num_counter_dict.items()\n",
    "    for ac_num, ac_num_count in ac_num_counter_list:\n",
    "        outfile.write(ac_num.strip()+ \" \" + str(ac_num_count)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e23ee",
   "metadata": {},
   "source": [
    "4\\. Improve the previous exercise by saving the accessions in order of occurrences with the top counts first in the file order5.acc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f532f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "make use of sorted() to complete the sort.\n",
    "\"\"\"\n",
    "# code\n",
    "\n",
    "ac_num_counter_dict = dict()\n",
    "with open(\"order5.acc\", \"w\") as outfile:\n",
    "    with open(\"ex5.acc\", \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line in ac_num_counter_dict:\n",
    "                # the value of the key is the counter.\n",
    "                ac_num_counter_dict[line] += 1\n",
    "            else:\n",
    "                # if this key is found for the first time,\n",
    "                # we set the value to be 1.\n",
    "                ac_num_counter_dict[line] = 1\n",
    "        # order the dict here:\n",
    "        # remember, the \"key\" in sorted, is that will be iterated over during the sort\n",
    "        ac_num_sorted_by_counter = sorted(ac_num_counter_dict.keys(), key=ac_num_counter_dict.get, reverse=True)\n",
    "           \n",
    "        ac_num_sorted_by_counter_dict = dict()\n",
    "        for ac_num in ac_num_sorted_by_counter:\n",
    "            ac_num_sorted_by_counter_dict[ac_num] = ac_num_counter_dict[ac_num]\n",
    "        # sanity check\n",
    "        #print(ac_num_sorted_by_counter_dict)\n",
    "    ac_num_sorted_list = ac_num_sorted_by_counter_dict.items()\n",
    "    for ac_num, ac_num_count in ac_num_sorted_list:\n",
    "        outfile.write(ac_num.strip()+\" \"+str(ac_num_count)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718aa2fa",
   "metadata": {},
   "source": [
    "5\\. In the tab-separated files slinger.txt and hoist.txt are two columns with an accession number and a numeric result; a probability between 0 and 1. The numbers are from running 2 different programs (slinger and hoist, if you are in doubt). You must combine these probabilities - basically taking the average of the two numbers - for each accession number and write the result in a file combined.txt. The file should look like the sources, i.e. tab-separated with accession in column 1 and number in column 2. Unfortunately, the two programs have not been run from the same set of accession numbers, so some of the results are only available in one of the input files. In such case you ignore/discard the data for that accession. Only save results in the output file when the accession is in both of the input files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c778a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code:\n",
    "\"\"\"\n",
    "def main()\n",
    "    s_h_avg_dict = make_avgs(slinger.txt, hoist.txt)\n",
    "    write dict out to file as instructed.\n",
    "\n",
    "\n",
    "def make_avgs(file1.txt, file2.txt):\n",
    "    initiate an empty dictionary\n",
    "    read file1 into a dictionary.\n",
    "    read file2 into a dictionary\n",
    "    make each file's key lists into a set\n",
    "    use the set method .interestion to find the common accession numbers, make into a list\n",
    "    use this list as the key for the empty dictionary\n",
    "        for key in list, the value would be the average of the values in file1 and file2.\n",
    "    return the s_h_avg_dict.\n",
    "\n",
    "call main\n",
    "\"\"\"\n",
    "# code\n",
    "def main():\n",
    "    s_h_avg_dict = make_avgs(\"slinger.txt\", \"hoist.txt\")\n",
    "    s_h_avg_items = s_h_avg_dict.items()\n",
    "    with open(\"combined.txt\", \"w\") as outfile:\n",
    "        for ac_num, avg in s_h_avg_items:\n",
    "            outfile.write(ac_num+\"\\t\"+str(avg)+\"\\n\")\n",
    "\n",
    "\n",
    "def make_avgs(file1, file2):\n",
    "    avg_dict = dict()\n",
    "    file1_dict = txt_to_dict(file1)\n",
    "    file2_dict = txt_to_dict(file2)\n",
    "    # list(.keys()) is the best way to convert .keys() to a list.\n",
    "    file1_dict_key_set = set(file1_dict.keys())\n",
    "    file2_dict_key_set = set(file2_dict.keys())\n",
    "    \n",
    "    shared_keys = (file1_dict_key_set.intersection(file2_dict_key_set))\n",
    "    for key in shared_keys:\n",
    "        values = (float(file1_dict[key]) + float(file2_dict[key]))/2\n",
    "        avg_dict[key] = '{:.3f}'.format(round(values, 3))\n",
    "    return avg_dict\n",
    "\n",
    "def txt_to_dict(some_file):\n",
    "    some_file_dict = dict()\n",
    "    with open(f\"{some_file}\", \"r\") as some_file_infile:\n",
    "        for line in some_file_infile:\n",
    "            col1 = line.split()[0]\n",
    "            col2 = line.split()[1]\n",
    "            some_file_dict[col1] = col2\n",
    "    return some_file_dict\n",
    "    # file1 sanity check :)\n",
    "    \n",
    "\n",
    "    print(some_file_dict)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0438db2",
   "metadata": {},
   "source": [
    "6\\. Using above method gives you too little data. You try this time to combine your two input sets differently. If an accession is in both input files you use the average, if it is in only one, you just use the number straight in the output file. This is effectively making a union of the input instead of an intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a720bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "Other parts of the code remain the same.\n",
    "Except for the avg_dict def.\n",
    "\n",
    "maybe something like, big set with all of the keys\n",
    "the for each key\n",
    "    if the key is in set1.intersection(set2):\n",
    "        the value for the avg[key] is the average.\n",
    "    if the key is in set1 but not set2:\n",
    "        avg[key] = set1[key]\n",
    "    if the key is in set2 but not set1:\n",
    "        avg[key] = set2[key]\n",
    "    \n",
    "\"\"\"\n",
    "# code\n",
    "def main():\n",
    "    s_h_avg_union_dict = make_avgs(\"slinger.txt\", \"hoist.txt\")\n",
    "    s_h_avg_union_items = s_h_avg_union_dict.items()\n",
    "    with open(\"combined_union.txt\", \"w\") as outfile:\n",
    "        for ac_num, avg in s_h_avg_union_items:\n",
    "            outfile.write(ac_num+\"\\t\"+str(avg)+\"\\n\")\n",
    "\n",
    "\n",
    "def make_avgs(file1, file2):\n",
    "    avg_dict = dict()\n",
    "    file1_dict = txt_to_dict(file1)\n",
    "    file2_dict = txt_to_dict(file2)\n",
    "    # list(.keys()) is the best way to convert .keys() to a list.\n",
    "    file1_dict_key_set = set(file1_dict.keys())\n",
    "    file2_dict_key_set = set(file2_dict.keys())\n",
    "    \n",
    "    all_keys = (file1_dict_key_set.union(file2_dict_key_set))\n",
    "    shared_keys = (file1_dict_key_set.intersection(file2_dict_key_set))\n",
    "    for key in all_keys:\n",
    "        if key in shared_keys:\n",
    "            values = (float(file1_dict[key]) + float(file2_dict[key]))/2\n",
    "            avg_dict[key] = '{:.3f}'.format(round(values, 3))\n",
    "        else:\n",
    "            # if it is not in file1, then it must ONLY be in file2.\n",
    "            if key not in file1_dict_key_set:\n",
    "                avg_dict[key] = file2_dict[key]\n",
    "            else:\n",
    "                pass\n",
    "            # if it is not in file2, then it must ONLY by in file1.\n",
    "            if key not in file2_dict_key_set:\n",
    "                avg_dict[key] = file1_dict[key]\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    return avg_dict\n",
    "\n",
    "def txt_to_dict(some_file):\n",
    "    some_file_dict = dict()\n",
    "    with open(f\"{some_file}\", \"r\") as some_file_infile:\n",
    "        for line in some_file_infile:\n",
    "            col1 = line.split()[0]\n",
    "            col2 = line.split()[1]\n",
    "            some_file_dict[col1] = col2\n",
    "    return some_file_dict\n",
    "    # file1 sanity check :)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
