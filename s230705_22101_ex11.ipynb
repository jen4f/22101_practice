{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b80bd32",
   "metadata": {},
   "source": [
    "## L11: Sets\n",
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5187645",
   "metadata": {},
   "source": [
    "1\\. Read the sequences in the file dna7.fsa. Find out which and how many of the 64 codons are not used somewhere in the sequences. Print the unused codons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93dabfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the unused codons out of all 64 possble codons: \n",
      "{'GTC', 'AAT', 'CGG', 'GAT', 'ACG', 'TAG', 'TCA', 'ACA', 'GTT', 'ATA', 'TTA', 'AAA', 'TTG', 'ATT', 'TTT', 'GTA', 'TGA', 'TAT', 'TAA', 'CGT', 'TCG', 'CGA'}\n",
      "There are 22 of them in total.\n"
     ]
    }
   ],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "read dna7.fsa file and create a list only containing the dna sequences, one item is one entire sequence.\n",
    "write a function to generate all 64 codons\n",
    "initiate an empty set of unused codons\n",
    "\n",
    "initiate an occurrence counter that is set to zero\n",
    "for codon in codons:\n",
    "    for position in length of the list of sequences:\n",
    "        if the codon is present in a sequence:\n",
    "            add one to the occurrance counter\n",
    "        else:\n",
    "            do nothing\n",
    "        if the occurance counter is equal to 0\n",
    "            add the codon to the unused codon set.\n",
    "\n",
    "display unused codons set.\n",
    "display length of unused codons set.\n",
    "\"\"\"\n",
    "# code\n",
    "def main():\n",
    "    seq = \"\"\n",
    "    with open(\"dna7.fsa\", \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                line = \"%\"\n",
    "            else:\n",
    "                pass\n",
    "            seq += line.strip()\n",
    "    seqs_list = seq.split(\"%\")\n",
    "    # now seq_list is a list of sequences, one item per sequence entry.\n",
    "    seqs_list.pop(0)\n",
    "\n",
    "    codons_set = make_all_codons([\"A\", \"T\", \"C\", \"G\"])\n",
    "    unused_codons_set = set()\n",
    "\n",
    "    for codon in codons_set:\n",
    "        for position in range(len(seqs_list)):\n",
    "            occurence = 0\n",
    "            if codon in seqs_list[position]:\n",
    "                occurence += 1\n",
    "            else:\n",
    "                pass\n",
    "            if occurence == 0:\n",
    "                unused_codons_set.add(codon)\n",
    "    print(\"These are the unused codons out of all 64 possble codons: \")\n",
    "    print(unused_codons_set)\n",
    "    print(f\"There are {len(unused_codons_set)} of them in total.\")\n",
    "\n",
    "\n",
    "# adopted code from https://www.geeksforgeeks.org/python-program-to-print-all-possible-combinations-from-the-three-digits/\n",
    "def make_all_codons(L):\n",
    "    codons_set = set()\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            for k in range(4):\n",
    "                    codon = L[i]+L[j]+L[k]\n",
    "                    codons_set.add(codon)\n",
    "    return(codons_set)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a9632",
   "metadata": {},
   "source": [
    "2\\. You have made a program (let's call it the X-program), which as input takes a file of accession numbers, start10.dat and produces some output, which is in res10.dat. Now you count the lines in your input file and your output file and you discover that the line numbers do not match. Horror - your program does not produce output for some input. Now the assignment is to discover which accession numbers did not produce output. This can be done in various ways, but now you have to use a set. Print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42181d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following accession numbers exist in start10.dat but not res10.dat: \n",
      "['AB000381.CDS.1', 'AB000905.CDS.1', 'AB001106.CDS.1', 'AB001325.CDS.1', 'AB002533.CDS.1', 'AC000061.CDS.3', 'AC002076.CDS.1', 'AC002076.CDS.2', 'AC002077.CDS.1', 'AC002115.CDS.3', 'AC002115.CDS.4', 'AF000231.CDS.1', 'AF000573.CDS.1', 'AF001620.CDS.1', 'AF002700.CDS.1', 'D12485.CDS.2', 'J02960.CDS.2', 'J05500.CDS.2', 'L00137.CDS.2', 'L08666.CDS.2', 'L10955.CDS.2', 'L42243.CDS.3', 'L44140.CDS.10', 'L44140.CDS.3', 'M10014.CDS.2', 'M13232.CDS.2', 'M13934.CDS.2', 'M14123.CDS.3', 'M14123.CDS.4', 'M16441.CDS.2', 'M21142.CDS.4', 'M22919.CDS.2', 'M24900.CDS.3', 'M37815.CDS.2', 'M83216.CDS.2', 'M91029.CDS.2', 'M95623.CDS.2', 'S39329.CDS.2', 'U01317.CDS.3', 'U01317.CDS.5', 'U01317.CDS.7', 'U12471.CDS.2', 'U17579.CDS.3', 'U22376.CDS.3', 'U22961.CDS.2', 'U22961.CDS.3', 'U30313.CDS.2', 'U47011.CDS.4', 'U62293.CDS.2', 'U65406.CDS.3', 'U68162.CDS.2', 'U78027.CDS.3', 'U89336.CDS.5', 'X05997.CDS.2', 'X16609.CDS.2', 'X17648.CDS.2', 'X62078.CDS.2', 'X65867.CDS.2', 'X66358.CDS.2', 'X66401.CDS.3', 'X66867.CDS.3', 'X72925.CDS.2', 'X76342.CDS.2', 'X89398.CDS.2', 'X90858.CDS.2', 'Y00318.CDS.2', 'Z24459.CDS.2', 'Z47556.CDS.2', 'Z68280.CDS.2', 'Z83821.CDS.2', 'Z83821.CDS.3', 'Z84721.CDS.4']\n"
     ]
    }
   ],
   "source": [
    "# pseudo code\n",
    "\"\"\"\n",
    "make two sets:\n",
    "one for the accession numbers in start10.dat;\n",
    "one for the accession numbers in res10.dat.\n",
    "\n",
    "use the mathematical properties of sets to find which accession numbers did not produce output.\n",
    "\"\"\"\n",
    "# code\n",
    "start_set = set()\n",
    "with open(\"start10.dat\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        start_set.add(line)\n",
    "\n",
    "res_set = set()\n",
    "with open(\"res10.dat\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip().split()[1]\n",
    "        res_set.add(line)\n",
    "\n",
    "# the accession numbers that did not produce output would be\n",
    "# those that \"start\" has but \"res\" does not have:\n",
    "# using difference:\n",
    "\n",
    "diff = start_set.difference(res_set)\n",
    "print(\"The following accession numbers exist in start10.dat but not res10.dat: \")\n",
    "print(sorted(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b580c7b",
   "metadata": {},
   "source": [
    "3\\. In the file ex5.acc are a lot of accession numbers, where some are duplicates. We have earlier cleaned this file of duplicates. Let's do that again using a set. Make a program that reads the file once, finds the unique accession numbers and write them to the file uniq5.acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d858cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo code:\n",
    "\"\"\"\n",
    "initiate an empty set\n",
    "read the file ex5.acc\n",
    "    add the accession numbers to the set\n",
    "\n",
    "sort the set and write it out as uniq5.acc\n",
    "\"\"\"\n",
    "# code:\n",
    "uniq5_set = set()\n",
    "with open(\"ex5.acc\", \"r\") as infile:\n",
    "    for line in infile:\n",
    "        uniq5_set.add(line.strip())\n",
    "\n",
    "with open(\"uniq5.acc\", \"w\") as outfile:\n",
    "    for item in uniq5_set:\n",
    "        outfile.write(item+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81c989",
   "metadata": {},
   "source": [
    "4\\. In the data1.gb file there are 6 references (to articles). Make a program that extracts all authors from the references, eliminates those that are duplicates and print the list of authors. You will notice that some authors seems to be the same person using different initials. You should only consider a person a duplicate if the name matches exactly. This should also work for the other Genbank entries: data2.gb, data3.gb & data4.gb.\n",
    "Beware: there traps in this exercise, check your output properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7f3364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a file name, for example data1-4.gb (STOP to quit): data2.gb\n",
      "\n",
      "Here are the unique author names in data2.gb in alphabetical order: \n",
      "['Ala-Kokko,L', 'Baldwin,C.T', 'Benson-Chanda,V', 'Bernard,M', 'Bernard,M.P', 'Bornstein,P', 'Bottenus,R.E', 'Chu,M.L', 'Conway,D', 'De Paepe,A', 'Di Liberto,M', 'Di, Liberto,M', 'Dickson,L', 'Dickson,L.A', 'Earley,J.J', 'Ganguly,A', 'Glaeser,D', 'Horton,W', 'Just,W', 'Kennerknecht,I', 'Korkko,J.M', 'Kuivaniemi,H', 'Martzen,M.R', 'Myers,J.C', 'Nuytinck,L', 'Pepe,G', 'Prockop,D.J', 'Ramirez,F', 'Sabol,C', 'Sangiorgi,F.O', 'Schwemmle,S', 'Sherwood,A.L', 'Sippola-Thiele,M', 'Strobel,D', 'Tromp,G', 'Trummer,T', 'Weil,D', 'and Prockop,D.J.,', 'de Wet,W', 'de Wet,W.J']\n",
      "Please enter a file name, for example data1-4.gb (STOP to quit): data1.gb\n",
      "\n",
      "Here are the unique author names in data1.gb in alphabetical order: \n",
      "['Bell,G.I', 'Brosius,J', 'Cordell,B', 'Dull,T.J', 'Goeddel,D.V', 'Goodman,H.M', 'Gray,A', 'Peter,S.,', 'Philips,J.A. III', 'Pictet,R', 'Pictet,R.L', 'Rutter,W.J', 'Selby,M.J', 'Sures,I', 'Swain,W.F', 'Tischer,E', 'Ullrich,A']\n",
      "Please enter a file name, for example data1-4.gb (STOP to quit): data3.gb\n",
      "\n",
      "Here are the unique author names in data3.gb in alphabetical order: \n",
      "['Deryckere,F', 'Gannon,F', 'McMorrow,T', 'McMorrow,T.,', 'Wagner,A']\n",
      "Please enter a file name, for example data1-4.gb (STOP to quit): data4.gb\n",
      "\n",
      "Here are the unique author names in data4.gb in alphabetical order: \n",
      "['Lioupis,A', 'Lioupis,A.,', 'Nevo,E', 'Wallis,M']\n",
      "Please enter a file name, for example data1-4.gb (STOP to quit): STOP\n"
     ]
    }
   ],
   "source": [
    "# pseudo code\n",
    "\n",
    "\"\"\"\n",
    "wrote a function which takes in a file and returns a sorted, uniq set of auth names.\n",
    "\n",
    "\"\"\"\n",
    "# code\n",
    "def main():\n",
    "    #prompt user for file name:\n",
    "    while True:\n",
    "        usr_file = input(\"Please enter a file name, for example data1-4.gb (STOP to quit): \")\n",
    "        if usr_file == \"STOP\":\n",
    "            break\n",
    "        else:\n",
    "            uniq_auth(usr_file)\n",
    "\n",
    "\n",
    "def uniq_auth(file):\n",
    "    with open(f\"{file}\", \"r\") as infile:\n",
    "        (authors, auth_flag) = (\"\", False)\n",
    "        for line in infile:\n",
    "            if line.startswith(\"  TITLE     \"):    #red\n",
    "                auth_flag = False\n",
    "            if line.startswith(\"  AUTHORS   \"):    #green\n",
    "                auth_flag = True\n",
    "            if auth_flag == True:\n",
    "                authors += line[11:]\n",
    "        if auth_flag:\n",
    "            raise ValueError(\"Format is not right. Can not trust result.\")\n",
    "        if len(authors) == 0:\n",
    "            raise ValueError(\"No data found. Can not trust result.\")\n",
    "        \n",
    "        \n",
    "        lines_corrected = (authors.replace(\". and\",\".,\").replace(\"\\n\",\",\")).strip().replace(\",,\",\",\")\n",
    "        # now, each individual name is separated by \".,\"\n",
    "        corrected_set = set(lines_corrected.split(\"., \"))\n",
    "        print()\n",
    "        print(f\"Here are the unique author names in {file} in alphabetical order: \")\n",
    "        print(sorted(corrected_set))\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
